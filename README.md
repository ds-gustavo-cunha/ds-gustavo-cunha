# **Gustavo Cunha**


*I built a **portfolio webpage** where I could display my projects in a more straightforward and personal way. You can check it on this link: [https://ds-gustavo-cunha.github.io/projects-portfolio/]( https://ds-gustavo-cunha.github.io/projects-portfolio/ ). However, you can also check a brief introduction below if you prefer to do so.* 😉
#


The main objective of this personal portfolio is to demonstrate my skills in **solving Data Science business challenges**.

<p align='center'>
  <img src="icon.svg" alt="drawing" width="200"/>  
</p>

# Gustavo Cunha
<sub>*Data scientist at [Hotmart](https://www.linkedin.com/company/hotmart/), Data science teacher at [Le Wagon](https://www.lewagon.com/), [AWS certified machine learning specialist](https://www.credly.com/badges/34baac5b-2344-4a43-b12d-33555d096406/public_url) and [AWS certified cloud practitioner](https://www.credly.com/badges/6f274a45-e7b0-4952-a4f9-029de6e02135/public_url), freelance and volunteer data scientist, Ex-Brazilian Navy officer*</sub>
<br>
<br>
<br>

<strong>Who am I?</strong> 😬

* I am a **self-disciplined**, **resilient**, and **ethical** person.

* I have a **military background** and a very curious and active mind.

* Some time ago, I fell in love with data science and, since then, I've been focusing my energy and time on projects to **solve business challenges** using **data science concepts** and **tools**.


<br>
<strong>What are the analytical tools I use in my projects?</strong> 🛠

* **Data Collect and Storage**: SQL, Postgres, MySQL, SQLite, ElasticSearch, MongoDB.

* **Coding**: Python, Spark.

* **Statistics**: Cohort Analysis, Descriptive Statistics, Inferential Statistics, Causal Inference, Survival Analysis. 

* **Development**: Git, Github, Gitlab, Linux, Continuous Integration.

* **Machine Learning and Deep Learning**: Classification, Regression, Clustering, NLP.

* **APIs**: Flask, FastAPI.

* **Machine Learning Deployment**: Heroku, Streamlit Cloud, Docker, Airflow, Google Sheets, Telegram.

* **Cloud Computing**: Amazon Web Services (AWS): (EC2, RDS, Lambda, DynamoDB, S3, Sagemaker); Google Cloud Platform (GCP): (Cloud Storage, Compute Engine, Container Registry, Cloud Run, AI Platform).

* **Data Visualization**: Metabase, Power BI, Streamlit.

<br>
<strong>AWS Certifications:</strong>

[![Linkedin Badge](aws-certified-machine-learning-specialty.png)](https://www.credly.com/badges/34baac5b-2344-4a43-b12d-33555d096406/public_url)

[![Medium Badge](aws-certified-cloud-practitioner.png)](https://www.credly.com/badges/6f274a45-e7b0-4952-a4f9-029de6e02135/public_url)

<br>

<strong>Links:</strong>

[![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=Linkedin&logoColor=white)](https://www.linkedin.com/in/ds-gustavo-cunha/)

[![Medium Badge](https://img.shields.io/badge/-Medium-12100E?style=for-the-badge&logo=Medium&logoColor=white)](https://medium.com/@ds-gustavo-cunha)

[![Gmail Badge](https://img.shields.io/badge/-Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white)](mailto:gcunhaj@gmail.com)

<br>

## Data Science Projects:

### [Bottomline]( https://github.com/ds-gustavo-cunha/Bottomline-Project )
We all live in a society that produces an overwhelming amount of information daily. Information per se is valuable but it's often very challenging to spotlight the essential part of it - the bottomline, so to say. This mental-filtering process can be very time-consuming and also confusing sometimes. With our technical solution, we provide an automated service that identifies the text's most relevant sentences to summarize the text. Additionally, the service provides the general sentiment (positive, neutral or negative) of the text. In other words, the final product will give the user a general idea about the text content as well as its most prominent sentiment.

### [Fraud Detection]( https://github.com/ds-gustavo-cunha/Fraud-Detection/tree/master/fraud_detection )
Blocker Fraud Company is a company specialized in the detection of fraud in financial transactions made through mobile devices. The company is expanding in Brazil and, to find new customers more quickly, it has adopted a very aggressive strategy. The strategy works as follows: (1) the company will receive 25% of each transaction value that was correctly detected as fraud; (2) The company will receive 5% of each transaction value that was detected as a fraud despite being legitimate; (3) The company will return 100% of each transaction value that was detected as legitimate despite being a fraud. The final solution includes a Power BI reporting dashboard with answers to business questions as well as a Docker container with API implementation, made with FasAPI and PySpark, and a MongoDB database with APIs requests saved for future analyses.

### [Insiders Project]( https://github.com/ds-gustavo-cunha/Insiders-Project/tree/master/Insiders_Clustering )
The All in One Place company is a multi-brand outlet company that sells second-line products of several brands at a lower price through e-commerce. Within just one year of operation, the marketing team realized that some customers buy more expensive products with high frequency and contribute to a significant portion of the company's revenue. This project aims to determine who are the customers eligible to participate in the Insiders program. Once this list is ready, the Marketing team will carry out a sequence of personalized and exclusive actions to this group of people to increase their sales and purchase frequency. The final solution answers business questions, validates business hypotheses, creates a reporting dashboard and implements a solution architecture in the AWS cloud.

### [Rossmann Store Sales]( https://github.com/ds-gustavo-cunha/Rossmann-Store-Sales/tree/master/rossmann_store_sales )
Rossmann is a company that operates over 3,000 drug stores in 7 European countries. Its products range includes up to 21,700 items and can vary depending on the size of the shop and the location. Rossmann store managers need daily sales predictions for up to six weeks in advance to plan infrastructure investments in their stores (will the next six weeks' sales be high enough to balance infrastructure investment?). The final solution for this problem is a Telegram bot where the user just needs to type the number of the store and the bot will quickly answer the sales prediction for this given store in the next six weeks. Besides, if the final user wants more detailed information about this six weeks prediction, he (she) could get further details on a data App, with an interactive chart, on sales prediction over these six weeks. Furthermore, on this data App, the user can also read the entire project overview to understand further how this prediction is made.

### [Health Insurance Cross-Sell]( https://github.com/ds-gustavo-cunha/Health-Insurance-Cross-Sell/tree/master/health_insurance_cross_sell )
Insurance All is a health insurance company and its products team is analyzing the possibility of offering a new product, automobile insurance, for its health insurance clients. Similar to its health insurance, customers of this new insurance plan would have to pay an annual plan to be insured by Insurance All in case of an eventual car accident or damage. In this project, I developed a Machine Learning algorithm that increases the number of contacted interested customers by 1,316 and 2,259 for 20,000 and 40,000 sales teams contacts so that the estimated revenue increases are respectively U$ 131,600 and U$ 225,900.

<br>

## Data Engineering Projects:

### [Synthetic Data Ingestion]( https://github.com/ds-gustavo-cunha/Synthetic-Data-Ingestion )
The idea is to create synthetic data regarding customer behaviour for two groups of customers: control and treatment. We would generate this behaviour with statistical distributions (e.g. Poisson and Gamma distributions) and would ingest both the created customer behaviour and the statistical distribution params in the architecture. The data would flow throughout the architecture, e.g. data ingestion layer, a bronze layer, a silver layer, etc. As the output, we would have the data regarding the customer behaviour and its statistical distribution blueprint. Then, we could use A/B testing tools to check if there is a statistically significant difference between the control and the treatment groups. However, once we know the original distribution of both groups, we know if they are different or not, so we will be able to check if the A/B tests would give us the correct result of not (especially regarding type I and type II errors).

<br>

## Problem Solving Mindset:

### [Problem Solving Checkpoints]( https://ds-gustavo-cunha.github.io/Problem-Solving-Checkpoints/ )
After reading many books, attending many courses and doing a bunch of data science projects, I felt the need to define how I should move from real-world problems to real-world solutions in a structured way. So, the purpose of this brief material is to share my initial summary of how to structure a problem-solving strategy. I emphasize that it is just my initial MVP about this subject. In other words, it is not supposed to be a definitive solution, not even to replace any already tested framework! I'm sharing this compilation so anyone interested in this topic can learn or remember something relevant to solve some real problem: if this happens somehow, I would be delighted!

<br>

## Medium Posts:

### [Six lessons I learnt during the last six months of data scientist experience](https://medium.com/@ds-gustavo-cunha/six-lessons-i-learnt-during-the-last-six-months-of-data-scientist-experience-b3943f1d46c6)
Sharing learnings throughout the last six months of data scientist experience.

### [Applying the Lean Startup mindset to data science projects](https://medium.com/@ds-gustavo-cunha/applying-the-lean-startup-mindset-to-data-science-projects-fdcd3ce44d10)
Applying some core concepts of “The Lean Startup: How Today’s Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses” by Eric Ries to make data science projects more effective.

### [Visual intelligence techniques applied on data science projects](https://medium.com/@ds-gustavo-cunha/visual-intelligence-techniques-applied-on-data-science-projects-2ed1423a1161)
Applying techniques of “Visual Intelligence: Sharpen Your Perception, Change our Life” by Amy E. Herman on Data Science Projects.
